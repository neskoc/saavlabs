{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3 Highway DQN rlagents",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neskoc/saavlabs/blob/main/Lab3/Lab3_Highway_DQN_rlagents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTBW2COTwOg_"
      },
      "source": [
        "Lab3 is based on highway-env https://github.com/eleurent/highway-env. In \n",
        "envs/highway_env.py, the vehicle is rewarded for reaching a high speed, staying on the rightmost lanes and avoiding collisions for in highway driving (highway-env). Your task is to add an additional term to penalize changing lanes. (Ideally we should penalize changing lanes to the left more than changing to the right, but this is a simplified exercise.) Please refer to envs/roundabout_env for reference.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1) Fork the highway-env repository to your own GitHub account, and modify highway_env.py. (if you are not familiar with GitHub, I recommend installing GitHub Desktop https://desktop.github.com.)\n",
        "\n",
        "2) Replace \n",
        "!pip install highway-env \n",
        "with path to your own repository:\n",
        "!pip install git+https://github.com/USERNAME/highway-env\n",
        "\n",
        "3) Train your agent for different values of lane_change_reward, and different environments with varying complexity, starting from the simplest:\n",
        "\n",
        "env.config[\"lane_change_reward\"] = 0\n",
        "\n",
        "env.config[\"vehicles_count\"] = 0\n",
        "\n",
        "env.config[\"lanes_count\"] = 2\n",
        "\n",
        "env.config[\"initial_lane_id\"] = 0\n",
        "\n",
        "In this simple environment, during testing the vehicle should switch to the right lane quickly and stay in the right lane. (It is possible for it to stay in the left lane during testing if your training num_episodes is too small, since the agent may not have had a chance to try the lane change action during training.)\n",
        "Try different values of lane_change_reward (e.g., -0.1, -1, -10, etc. note that it must be negative), and different numbers of vehicles/lanes. Make lane_change_reward very negative until you observe that the vehicle prefers *collision* to *lane change to avoid collision*. Submit your IPython Notebook, and a short report (or text blocks within the Notebook) describing the different configurations you have tried, and your observations for each config, including two configs that differ only in the lane_change_reward, one with no or rare collisions, one with frequent collisions. Please share your Colab link with the trained model and the recorded videos for the testing in IPython Notebook, so we do not have to re-train the models (unless you are not using Colab, then upload your IPython Notebook or .py file to Canvas). \n",
        "\n",
        "Notes: \n",
        "\n",
        "1) More complex environments demand more training time (more num_episodes), so do not make your environment more complex than necessary. You may try increasing the  vehicles_density and reward_speed_range to increase the chances of collision. You may also find \"Script to Stop Google Colab From Disconnecting\" to be helpful.\n",
        "\n",
        "2) You may want to tune DQN hyperparams in configs/HighwayEnv/agents/DQNAgent/dqn.json, e.g., discount factor gamma, and epsilon greedy exploration params tau, temperature, final_temperature for different num_episodes.\n",
        "\n",
        "3) The error message \"fatal: destination path 'highway-env' already exists and is not an empty directory\" in the first code cell can be safely ignored.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sepDWoBqdRMK"
      },
      "source": [
        "# Training a DQN on `highway-v0` with rlagents\n",
        "## Import requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx8X4s8krNWt",
        "outputId": "d27cbb80-1c4b-4d65-b719-fa32b7f8fbf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Environment\n",
        "#pip install highway-env\n",
        "!pip install git+https://github.com/neskoc/highway-env\n",
        "import gym\n",
        "import highway_env\n",
        "\n",
        "# Agent\n",
        "!pip install git+https://github.com/eleurent/rl-agents\n",
        "\n",
        "# Visualisation utils\n",
        "import sys\n",
        "%load_ext tensorboard\n",
        "!pip install tensorboardx gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb python-opengl ffmpeg\n",
        "!git clone https://github.com/eleurent/highway-env.git\n",
        "sys.path.insert(0, '/content/highway-env/scripts/')\n",
        "from utils import show_videos"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/neskoc/highway-env\n",
            "  Cloning https://github.com/neskoc/highway-env to /tmp/pip-req-build-44lvoqhd\n",
            "  Running command git clone -q https://github.com/neskoc/highway-env /tmp/pip-req-build-44lvoqhd\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): highway-env==1.2 from git+https://github.com/neskoc/highway-env in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (from highway-env==1.2) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from highway-env==1.2) (3.2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from highway-env==1.2) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from highway-env==1.2) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from highway-env==1.2) (1.1.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env==1.2) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env==1.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env==1.2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env==1.2) (0.10.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->highway-env==1.2) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->highway-env==1.2) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->highway-env==1.2) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->highway-env==1.2) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->highway-env==1.2) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->highway-env==1.2) (0.16.0)\n",
            "Building wheels for collected packages: highway-env\n",
            "  Building wheel for highway-env (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for highway-env: filename=highway_env-1.2-cp37-none-any.whl size=92221 sha256=60eeec0313d075f2c3c673f0fbda885a078fb0cb0fc83b870b82705bc6131eb6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kfhdqbxu/wheels/3d/5a/fa/a5935b7fb89bd329a8df1fe050305501291bbcf949beda941c\n",
            "Successfully built highway-env\n",
            "Collecting git+https://github.com/eleurent/rl-agents\n",
            "  Cloning https://github.com/eleurent/rl-agents to /tmp/pip-req-build-69o12gu7\n",
            "  Running command git clone -q https://github.com/eleurent/rl-agents /tmp/pip-req-build-69o12gu7\n",
            "Requirement already satisfied (use --upgrade to upgrade): rl-agents==1.0.dev0 from git+https://github.com/eleurent/rl-agents in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.1.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.51.2)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.8.1+cu101)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->rl-agents==1.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->rl-agents==1.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->rl-agents==1.0.dev0) (1.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->rl-agents==1.0.dev0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->rl-agents==1.0.dev0) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->rl-agents==1.0.dev0) (57.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->rl-agents==1.0.dev0) (0.34.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rl-agents==1.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rl-agents==1.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rl-agents==1.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->rl-agents==1.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->rl-agents==1.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->rl-agents==1.0.dev0) (0.16.0)\n",
            "Building wheels for collected packages: rl-agents\n",
            "  Building wheel for rl-agents (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl-agents: filename=rl_agents-1.0.dev0-cp37-none-any.whl size=114561 sha256=c8929ff9e4d6b3ff1a8b9be1873a9bfb7a46363caa1b960aa55bd0b6c3ea7ee8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rh8m89am/wheels/be/14/44/bc2b8a73d904f2a421fde80db171e2bae90dfee95f293befca\n",
            "Successfully built rl-agents\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.12.4)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (57.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "fatal: destination path 'highway-env' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvOEW00pdHrG"
      },
      "source": [
        "## Training\n",
        "\n",
        "Prepare environment, agent, and evaluation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QowKW3ix45ZW",
        "outputId": "ea3b43c6-b3dd-42f1-dfd0-c49a0a700e65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from rl_agents.trainer.evaluation import Evaluation\n",
        "from rl_agents.agents.common.factory import load_agent, load_environment\n",
        "\n",
        "# Get the environment and agent configurations from the rl-agents repository\n",
        "!git clone https://github.com/eleurent/rl-agents.git\n",
        "%cd /content/rl-agents/scripts/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'rl-agents' already exists and is not an empty directory.\n",
            "/content/rl-agents/scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m8C7GUhdZ1l"
      },
      "source": [
        "import json\n",
        "\n",
        "def load_and_print_json(file):\n",
        "    # Opening JSON file\n",
        "    f = open(file,)\n",
        "\n",
        "    # returns JSON object as \n",
        "    # a dictionary\n",
        "    data = json.load(f)\n",
        "    print(file)\n",
        "    print(json.dumps(data, indent=4, sort_keys=True))\n",
        "\n",
        "    # Closing file\n",
        "    f.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kta171leAum",
        "outputId": "1d89f662-9e82-49d5-a96b-e2e9ced5e88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "import pprint\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "env_config = 'configs/HighwayEnv/env.json'\n",
        "agent_config = 'configs/HighwayEnv/agents/DQNAgent/dqn.json'\n",
        "load_and_print_json(agent_config)\n",
        "\n",
        "env = load_environment(env_config)\n",
        "np.random.seed(42)\n",
        "env.seed(42)\n",
        "\n",
        "\n",
        "num_episodes = 30\n",
        "num_episodes = 30\n",
        "env.config[\"lane_change_reward\"] = -0.01\n",
        "env.config[\"vehicles_count\"] = 50\n",
        "env.config[\"lanes_count\"] = 2\n",
        "env.config[\"initial_lane_id\"] = 0\n",
        "env.config[\"show_trajectories\"] = True\n",
        "# env.config[\"high_speed_reward\"] = 0.7\n",
        "# env.config[\"vehicles_density\"] = 1.2\n",
        "# env.config['reward_speed_range'] = [60, 100]\n",
        "env.config[\"collision_reward\"] = -100\n",
        "#env.config['reward_speed_range'] = [0, 100]\n",
        "pprint.pprint(env.config)\n",
        "pprint.pprint(agent_config)\n",
        "\n",
        "env.reset()\n",
        "plt.imshow(env.render(mode=\"rgb_array\"))\n",
        "plt.show()\n",
        "\n",
        "agent = load_agent(agent_config, env)\n",
        "evaluation = Evaluation(env, agent, num_episodes=num_episodes, display_env=True)\n",
        "print(f\"Ready to train {agent} on {env}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "configs/HighwayEnv/agents/DQNAgent/dqn.json\n",
            "{\n",
            "    \"__class__\": \"<class 'rl_agents.agents.deep_q_network.pytorch.DQNAgent'>\",\n",
            "    \"batch_size\": 32,\n",
            "    \"double\": false,\n",
            "    \"exploration\": {\n",
            "        \"final_temperature\": 0.05,\n",
            "        \"method\": \"EpsilonGreedy\",\n",
            "        \"tau\": 6000,\n",
            "        \"temperature\": 1.0\n",
            "    },\n",
            "    \"gamma\": 0.8,\n",
            "    \"loss_function\": \"l2\",\n",
            "    \"memory_capacity\": 15000,\n",
            "    \"model\": {\n",
            "        \"layers\": [\n",
            "            256,\n",
            "            256\n",
            "        ],\n",
            "        \"type\": \"MultiLayerPerceptron\"\n",
            "    },\n",
            "    \"n_steps\": 1,\n",
            "    \"target_update\": 50\n",
            "}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b0f8a8a583f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtK9dtfb0JMF"
      },
      "source": [
        "Start training. Run tensorboard locally to visualize training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFVq1gFz42Eg"
      },
      "source": [
        "%tensorboard --logdir \"{evaluation.directory}\"\n",
        "evaluation.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lNvWg42RWiw"
      },
      "source": [
        "Progress can be visualised in the tensorboard cell above, which should update every 30s (or manually). You may need to click the *Fit domain to data* buttons below each graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKfvu5uhzCIU"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Run the learned policy for a few episodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY0rpVYUtRpN"
      },
      "source": [
        "#env = load_environment(env_config)\n",
        "env.configure({\"offscreen_rendering\": True})\n",
        "agent = load_agent(agent_config, env)\n",
        "evaluation = Evaluation(env, agent, num_episodes=3, recover=True)\n",
        "evaluation.test()\n",
        "show_videos(evaluation.run_directory)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}